apiVersion: v1
kind: Pod
metadata:
  name: cached
spec:
  containers:
    - args:
        - -c
        - import torch; print(torch.cuda.is_available()); print(torch.cuda.device_count())
      command:
        - python3
      image: nvcr.io/nvidia/pytorch:25.02-py3
      imagePullPolicy: IfNotPresent
      name: example
      resources:
        limits:
          nvidia.com/gpu: "1"
  nodeSelector:
    ml-container-cache: "true"
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
